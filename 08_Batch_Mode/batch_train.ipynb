{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f23a4063",
   "metadata": {},
   "source": [
    "## Batch processing for pty-co-SAXSNN training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed663984",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from numpy.fft import fft2, fftshift\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "from loss_functions import NPCC_loss_symmetry_penalty, NPCC_loss, L1_loss, L2_loss\n",
    "\n",
    "plt.rcParams[\"image.cmap\"] = \"jet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a5286",
   "metadata": {},
   "source": [
    "## Script for running batch processing of different configurations of pty-co-SAXSNN\n",
    "\n",
    "Directory 'batch_mode_250' contains trained versions of pty-co-SAXSNN used for manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0350cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path\n",
    "# path = Path(\"Y:/ptychosaxs\")  # /net/micdata/data2/12IDC mounted windows drive\n",
    "path = Path(\"/net/micdata/data2/12IDC/ptychosaxs/\")\n",
    "#path = Path(\"/scratch/\")\n",
    "# Join paths\n",
    "MODEL_SAVE_PATH = path / 'batch_mode_250/trained_model/' # Automatically adds the correct separator\n",
    "if (not os.path.isdir(MODEL_SAVE_PATH)):\n",
    "    os.mkdir(MODEL_SAVE_PATH)\n",
    "print(MODEL_SAVE_PATH)\n",
    "\n",
    "\n",
    "lattice_list=['ClathII']#,'SC',]\n",
    "noise_list=['Noise','noNoise']\n",
    "unet_status_list=['no_Unet','Unet']\n",
    "loss_function_list=['pearson_loss','L2','L1']\n",
    "probe_size_list=[256]#[128,256]\n",
    "\n",
    "numDPs_list=[9600]\n",
    "symmetry_weight=0.0\n",
    "\n",
    "# For full training\n",
    "EPOCHS = 250\n",
    "# Specify which GPUs to use (e.g. GPUs 1 and 2)\n",
    "selected_gpus = [0,1]  # Select GPUs (0, 1, 2, or 3)\n",
    "NGPUS = len(selected_gpus)\n",
    "#NGPUS = torch.cuda.device_count() # if all GPUs are used\n",
    "BATCH_SIZE = NGPUS*16\n",
    "LR = NGPUS * 1e-3\n",
    "print(\"GPUs:\", NGPUS, \"Batch size:\", BATCH_SIZE, \"Learning rate:\", LR)\n",
    "no_probe=True\n",
    "\n",
    "# Add the models directory to the path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../src/models/')))\n",
    "\n",
    "\n",
    "\n",
    "for probe_size in probe_size_list:\n",
    "    for lattice in lattice_list:\n",
    "        for noise in noise_list:\n",
    "            directory=f'Lattice{lattice}_Probe{probe_size}x{probe_size}_ZCB_9_3D__{noise}_sim_ZCB_9_3D_S5065_N600_steps4_dp256'\n",
    "            print(directory)\n",
    "            # Load the data\n",
    "            #data_path = os.path.abspath(os.path.join(os.getcwd(), f'/scratch/preprocessed_sim_{directory}.npz'))\n",
    "            data_path = f'/net/micdata/data2/12IDC/ptychosaxs/batch_mode/preprocessed/preprocessed_sim_{directory}.npz'\n",
    "            print('Loading data from:', data_path)\n",
    "            data = np.load(data_path)\n",
    "\n",
    "            # Extract the arrays\n",
    "            amp_conv_red = data['amp_conv_red']\n",
    "            amp_ideal_red = data['amp_ideal_red']\n",
    "            amp_probe_red = data['amp_probe_red']\n",
    "            \n",
    "            # Set the number of patterns in test, train or validation set\n",
    "            NTEST = amp_conv_red.shape[0]//4\n",
    "            NTRAIN = amp_conv_red.shape[0]-NTEST\n",
    "            NVALID = NTEST//2 # NTRAIN//\n",
    "\n",
    "            print(NTRAIN,NTEST,NVALID)\n",
    "\n",
    "            H,W=amp_ideal_red[0].shape[0],amp_ideal_red[0].shape[1]\n",
    "            print(H,W)\n",
    "            \n",
    "            tst_start = amp_conv_red.shape[0]-NTEST\n",
    "\n",
    "            #separate data and convert to tensors and shuf\n",
    "            X_train = amp_conv_red[:NTRAIN].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "            X_test = amp_conv_red[tst_start:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "\n",
    "            Xp_train = amp_probe_red[:NTRAIN].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "            Xp_test = amp_probe_red[tst_start:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "\n",
    "            Y_I_train = amp_ideal_red[:NTRAIN].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "            Y_I_test = amp_ideal_red[tst_start:].reshape(-1,H,W)[:,np.newaxis,:,:]\n",
    "\n",
    "            ntrain=X_train.shape[0]\n",
    "            ntest=X_test.shape[0]\n",
    "\n",
    "            X_train, Xp_train, Y_I_train = shuffle(X_train, Xp_train, Y_I_train, random_state=0)\n",
    "\n",
    "            #Training data\n",
    "            X_train_tensor = torch.Tensor(X_train)\n",
    "            Xp_train_tensor = torch.Tensor(Xp_train) \n",
    "            Y_I_train_tensor = torch.Tensor(Y_I_train) \n",
    "\n",
    "            #Test data\n",
    "            X_test_tensor = torch.Tensor(X_test)\n",
    "            Xp_test_tensor = torch.Tensor(Xp_test) \n",
    "            Y_I_test_tensor = torch.Tensor(Y_I_test) \n",
    "\n",
    "            print(X_train_tensor.shape,Xp_train_tensor.shape, Y_I_train_tensor.shape)\n",
    "\n",
    "            if no_probe:\n",
    "                train_data = TensorDataset(X_train_tensor,Y_I_train_tensor)\n",
    "                test_data = TensorDataset(X_test_tensor,Xp_test_tensor)\n",
    "            else:\n",
    "                train_data = TensorDataset(X_train_tensor,Xp_train_tensor,Y_I_train_tensor)\n",
    "                test_data = TensorDataset(X_test_tensor,Xp_test_tensor)\n",
    "\n",
    "            N_TRAIN = X_train_tensor.shape[0]\n",
    "\n",
    "            train_data2, valid_data = torch.utils.data.random_split(train_data,[N_TRAIN-NVALID,NVALID])\n",
    "            print(len(train_data2),len(train_data2[0]),len(valid_data),len(test_data))\n",
    "\n",
    "            #download and load training data\n",
    "            trainloader = DataLoader(train_data2, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "            validloader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "            #same for test\n",
    "            #download and load training data\n",
    "            testloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "            \n",
    "            \n",
    "            for unet_status in unet_status_list:\n",
    "                    \n",
    "                for loss_function in loss_function_list:\n",
    "                    \n",
    "\n",
    "                    # First, try to import the module\n",
    "                    if unet_status=='no_Unet':\n",
    "                        try:\n",
    "                            import encoder1_no_Unet\n",
    "                            # Force reload the module\n",
    "                            importlib.reload(encoder1_no_Unet)\n",
    "                            # Now import the class from the freshly reloaded module\n",
    "                            from encoder1_no_Unet import recon_model\n",
    "                            print(\"Successfully imported recon_model_no_Unet\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Import error: {e}\")\n",
    "                    else:\n",
    "                        #First, try to import the module\n",
    "                        try:\n",
    "                            import encoder1\n",
    "                            importlib.reload(encoder1)\n",
    "                            # Now import the class from the freshly reloaded module\n",
    "                            from encoder1 import recon_model\n",
    "                            print(\"Successfully imported recon_model_Unet\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Import error: {e}\")\n",
    "\n",
    "\n",
    "                    model = recon_model()\n",
    "\n",
    "                    \n",
    "                    if no_probe:\n",
    "                        for ampsI,ampsO in trainloader:\n",
    "                            print(\"batch size:\", ampsI.shape)\n",
    "                            amp = model(ampsI)#,ampsP)\n",
    "                            print(amp.shape)\n",
    "                            print(amp.dtype)\n",
    "                            break\n",
    "                    else:\n",
    "                        for ampsI,ampsP,ampsO in trainloader:\n",
    "                            print(\"batch size:\", ampsI.shape)\n",
    "                            amp = model(ampsI,ampsP)\n",
    "                            print(amp.shape)\n",
    "                            print(amp.dtype)\n",
    "                            break    \n",
    "\n",
    "                    device = torch.device(f\"cuda:{selected_gpus[0]}\" if torch.cuda.is_available() else \"cpu\")\n",
    "                    device_ids = selected_gpus  # This will use only the specified GPUs\n",
    "\n",
    "                    if NGPUS > 1:\n",
    "                        print(\"Let's use\", NGPUS, \"GPUs!\")\n",
    "                        model = nn.DataParallel(model, device_ids=device_ids)  # Explicitly specify which GPUs to use\n",
    "\n",
    "                    model = model.to(device)\n",
    "                    print(model)        \n",
    "            \n",
    "                    print(f'{directory}_{unet_status}_{loss_function}')\n",
    "                    \n",
    "                    #Optimizer details\n",
    "                    iterations_per_epoch = np.floor((NTRAIN-NVALID)/BATCH_SIZE)+1 #Final batch will be less than batch size\n",
    "                    step_size = 6*iterations_per_epoch \n",
    "                    print(iterations_per_epoch)\n",
    "                    print(\"LR step size is:\", step_size, \"which is every %d epochs\" %(step_size/iterations_per_epoch))\n",
    "\n",
    "\n",
    "\n",
    "                    if loss_function=='L1':\n",
    "                        criterion = L1_loss#nn.L1Loss()\n",
    "                    elif loss_function=='L2':\n",
    "                        criterion = L2_loss#nn.MSELoss()\n",
    "                    else:\n",
    "                        print('Using pearson_loss')\n",
    "                        \n",
    "\n",
    "                    optimizer = torch.optim.Adam(model.parameters(), lr = LR, weight_decay=1e-5)\n",
    "                    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=LR/10, max_lr=LR, step_size_up=step_size,\n",
    "                                                                cycle_momentum=False, mode='triangular2')\n",
    "                                                                \n",
    "                                                                \n",
    "                    #Function to update saved model if validation loss is minimum\n",
    "                    print('Model string path')\n",
    "                    print(f'{directory}_{unet_status}_{loss_function}_symmetry_{symmetry_weight}.pth')\n",
    "                    def update_saved_model(model, path, current_epoch, best_val_loss):\n",
    "                        if not os.path.isdir(path):\n",
    "                            os.mkdir(path)\n",
    "                        \n",
    "                        # Save the best overall model\n",
    "                        if (NGPUS>1):    \n",
    "                            torch.save(model.module.state_dict(), path / f'best_model_{directory}_{unet_status}_{loss_function}_symmetry_{symmetry_weight}.pth')\n",
    "                        else:\n",
    "                            torch.save(model.state_dict(), path / f'best_model_{directory}_{unet_status}_{loss_function}_symmetry_{symmetry_weight}.pth')\n",
    "                        \n",
    "                        # Define epoch intervals (50, 100, 150, etc.)\n",
    "                        epoch_intervals = [2, 10, 25, 50, 100, 150, 200, 250]#, 300, 400, 500]\n",
    "                        \n",
    "                        # For each interval, save the best model within that interval\n",
    "                        for interval in epoch_intervals:\n",
    "                            if current_epoch <= interval:\n",
    "                                # Create a filename that includes the epoch interval\n",
    "                                interval_filename = f'best_model_{directory}_{unet_status}_epoch_{interval}_{loss_function}_symmetry_{symmetry_weight}.pth'\n",
    "                                interval_path = path / interval_filename\n",
    "                                \n",
    "                                # If this is the first time we're saving for this interval, save the model\n",
    "                                if not interval_path.exists():\n",
    "                                    if (NGPUS>1):\n",
    "                                        torch.save(model.module.state_dict(), interval_path)\n",
    "                                    else:\n",
    "                                        torch.save(model.state_dict(), interval_path)\n",
    "                                    print(f\"Saving best model for epoch interval {interval} at epoch {current_epoch}\")\n",
    "                                # If we already have a model for this interval, only update if the current loss is better\n",
    "                                else:\n",
    "                                    # Load the previous best loss for this interval\n",
    "                                    prev_loss_path = path / f'best_loss_epoch_{directory}_{unet_status}_{interval}_{loss_function}_symmetry_{symmetry_weight}.txt'\n",
    "                                    if prev_loss_path.exists():\n",
    "                                        with open(prev_loss_path, 'r') as f:\n",
    "                                            prev_best_loss = float(f.read().strip())\n",
    "                                        \n",
    "                                        # Update if current loss is better\n",
    "                                        if best_val_loss < prev_best_loss:\n",
    "                                            if (NGPUS>1):\n",
    "                                                torch.save(model.module.state_dict(), interval_path)\n",
    "                                            else:\n",
    "                                                torch.save(model.state_dict(), interval_path)\n",
    "                                            with open(prev_loss_path, 'w') as f:\n",
    "                                                f.write(str(best_val_loss))\n",
    "                                            print(f\"Updating best model for epoch interval {interval} at epoch {current_epoch}\")\n",
    "                                    else:\n",
    "                                        # First time saving for this interval\n",
    "                                        if (NGPUS>1):\n",
    "                                            torch.save(model.module.state_dict(), interval_path)\n",
    "                                        else:\n",
    "                                            torch.save(model.state_dict(), interval_path)\n",
    "                                        with open(prev_loss_path, 'w') as f:\n",
    "                                            f.write(str(best_val_loss))\n",
    "                                        print(f\"Saving best model for epoch interval {interval} at epoch {current_epoch}\")\n",
    "\n",
    "\n",
    "\n",
    "                    def train(trainloader,metrics):\n",
    "                        tot_loss = 0.0\n",
    "                        tot_loss_amp = 0.0\n",
    "                        tot_loss_symmetry = 0.0\n",
    "                        \n",
    "                        for i, (ft_images,amps) in tqdm(enumerate(trainloader)):\n",
    "                            ft_images = ft_images.to(device) #Move everything to device\n",
    "                            amps = amps.to(device)\n",
    "                            pred_amps = model(ft_images) #Forward pass\n",
    "                            \n",
    "                            #Compute losses\n",
    "                            #loss_a = criterion(pred_amps,amps) #Monitor amplitude loss\n",
    "                            if loss_function=='pearson_loss':\n",
    "                                loss_a,loss_pearson,loss_symmetry = NPCC_loss_symmetry_penalty(pred_amps,amps)#pearson_loss(pred_amps,amps)\n",
    "                            else:\n",
    "                                loss_a = criterion(pred_amps,amps)\n",
    "                            loss = loss_a #Use equiweighted amps and phase\n",
    "\n",
    "                            #Zero current grads and do backprop\n",
    "                            optimizer.zero_grad() \n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            \n",
    "                            if loss_function=='pearson_loss':\n",
    "                                tot_loss += loss.detach().item()\n",
    "                                tot_loss_amp += loss_pearson.detach().item()\n",
    "                                tot_loss_symmetry += loss_symmetry.detach().item()\n",
    "                            else:\n",
    "                                tot_loss += loss.detach().item()\n",
    "\n",
    "                            #Update the LR according to the schedule -- CyclicLR updates each batch\n",
    "                            scheduler.step() \n",
    "                            metrics['lrs'].append(scheduler.get_last_lr())\n",
    "                            \n",
    "                            \n",
    "                        #Divide cumulative loss by number of batches-- sli inaccurate because last batch is different size\n",
    "                        if loss_function=='pearson_loss':\n",
    "                            metrics['losses'].append([tot_loss/i,tot_loss_amp/i,tot_loss_symmetry/i]) \n",
    "                        else:\n",
    "                            metrics['losses'].append([tot_loss/i]) \n",
    "                        \n",
    "                    def validate(validloader,metrics):\n",
    "                        tot_val_loss = 0.0\n",
    "                        tot_val_loss_amp = 0.0\n",
    "                        tot_val_loss_symmetry = 0.0\n",
    "                        for j, (ft_images,amps) in enumerate(validloader):\n",
    "                            ft_images = ft_images.to(device)\n",
    "                            amps = amps.to(device)\n",
    "                            pred_amps = model(ft_images) #Forward pass\n",
    "                            \n",
    "                            if loss_function=='pearson_loss':   \n",
    "                                val_loss_a,val_loss_pearson,val_loss_symmetry = NPCC_loss_symmetry_penalty(pred_amps,amps)#pearson_loss(pred_amps,amps)\n",
    "                            else:\n",
    "                                val_loss_a = criterion(pred_amps,amps)\n",
    "                            \n",
    "                            val_loss = val_loss_a\n",
    "                        \n",
    "                            if loss_function=='pearson_loss':\n",
    "                                tot_val_loss += val_loss.detach().item()\n",
    "                                tot_val_loss_amp += val_loss_pearson.detach().item()\n",
    "                                tot_val_loss_symmetry += val_loss_symmetry.detach().item()\n",
    "                            else:\n",
    "                                tot_val_loss += val_loss.detach().item()\n",
    "                        \n",
    "                        if loss_function=='pearson_loss':\n",
    "                            metrics['val_losses'].append([tot_val_loss/j,tot_val_loss_amp/j,tot_val_loss_symmetry/j])\n",
    "                        else:\n",
    "                            metrics['val_losses'].append([tot_val_loss/j])\n",
    "                    \n",
    "                        #Update saved model if val loss is lower\n",
    "                        if(tot_val_loss/j<metrics['best_val_loss']):\n",
    "                            print(\"Saving improved model after Val Loss improved from %.5f to %.5f\" %(metrics['best_val_loss'],tot_val_loss/j))\n",
    "                            metrics['best_val_loss'] = tot_val_loss/j\n",
    "                            update_saved_model(model, MODEL_SAVE_PATH, metrics['current_epoch'], tot_val_loss/j)\n",
    "                        \n",
    "                    # Initialize metrics dictionary with current_epoch\n",
    "                    metrics = {\n",
    "                        'losses': [],\n",
    "                        'val_losses': [],\n",
    "                        'lrs': [],\n",
    "                        'best_val_loss': float('inf'),\n",
    "                        'current_epoch': 0\n",
    "                    }\n",
    "\n",
    "                    for epoch in range(EPOCHS):\n",
    "                        metrics['current_epoch'] = epoch  # Update current epoch in metrics\n",
    "                        \n",
    "                        #Set model to train mode\n",
    "                        model.train() \n",
    "                        #Training loop\n",
    "                        train(trainloader,metrics)\n",
    "                        \n",
    "                        #Switch model to eval mode\n",
    "                        model.eval()\n",
    "                        \n",
    "                        #Validation loop\n",
    "                        validate(validloader,metrics)\n",
    "                        if loss_function=='pearson_loss':\n",
    "                            print('Epoch: %d | Total  | Train Loss: %.5f | Val Loss: %.5f' %(epoch, metrics['losses'][-1][0], metrics['val_losses'][-1][0]))\n",
    "                            print('Epoch: %d | Amp | Train Loss: %.5f | Val Loss: %.5f' %(epoch, metrics['losses'][-1][1], metrics['val_losses'][-1][1]))\n",
    "                            print('Epoch: %d | Symmetry | Train Loss: %.5f | Val Loss: %.5f' %(epoch, metrics['losses'][-1][2], metrics['val_losses'][-1][2]))\n",
    "                            print('Epoch: %d | Ending LR: %.6f ' %(epoch, metrics['lrs'][-1][0]))\n",
    "                        else:\n",
    "                            print('Epoch: %d | Total  | Train Loss: %.5f | Val Loss: %.5f' %(epoch, metrics['losses'][-1][0], metrics['val_losses'][-1][0]))\n",
    "                            print('Epoch: %d | Ending LR: %.6f ' %(epoch, metrics['lrs'][-1][0]))\n",
    "                            \n",
    "                    batches = np.linspace(0,len(metrics['lrs']),len(metrics['lrs'])+1)\n",
    "                    epoch_list = batches/iterations_per_epoch\n",
    "\n",
    "                    plt.plot(epoch_list[1:],metrics['lrs'], 'C3-')\n",
    "                    plt.grid()\n",
    "                    plt.ylabel(\"Learning rate\")\n",
    "                    plt.xlabel(\"Epoch\")\n",
    "\n",
    "                    losses_arr = np.array(metrics['losses'])\n",
    "                    val_losses_arr = np.array(metrics['val_losses'])\n",
    "                    losses_arr.shape\n",
    "                    fig, ax = plt.subplots(1,sharex=True, figsize=(15, 8))\n",
    "                    ax.plot(losses_arr[:,0], 'C3o-', label = \"Total Train loss\")\n",
    "                    ax.plot(val_losses_arr[:,0], 'C0o-', label = \"Total Val loss\")\n",
    "                    ax.set(ylabel='Loss')\n",
    "                    ax.grid()\n",
    "                    ax.legend(loc='center right', bbox_to_anchor=(1.5, 0.5))\n",
    "                    plt.tight_layout()\n",
    "                    plt.xlabel(\"Epochs\")\n",
    "                    #plt.savefig(f'/scratch/plots/{directory}_{unet_status}_{loss_function}_symmetry_{symmetry_weight}_train_loss.png', bbox_inches='tight', dpi=300)\n",
    "                    plt.savefig(f'/net/micdata/data2/12IDC/ptychosaxs/batch_mode_250/plots/{directory}_{unet_status}_{loss_function}_symmetry_{symmetry_weight}_train_loss.png', bbox_inches='tight', dpi=300)\n",
    "                    plt.close()\n",
    "                    #plt.show()\n",
    "                                            \n",
    "\n",
    "                    model.eval()\n",
    "                    results = []\n",
    "                    for i, test in enumerate(testloader):\n",
    "                        tests = test[0].to(device)\n",
    "                        testsp = test[1].to(device)\n",
    "                        result = model(tests)\n",
    "                        for j in range(tests.shape[0]):\n",
    "                            results.append(result[j].detach().to(\"cpu\").numpy())\n",
    "                            \n",
    "                    results = np.array(results).squeeze()\n",
    "\n",
    "                    h,w = H,W\n",
    "                    ntest=results.shape[0]\n",
    "                    plt.figure()\n",
    "                    n = 5\n",
    "                    f,ax=plt.subplots(4,n,figsize=(15, 12))\n",
    "                    plt.gcf().text(0.02, 0.8, \"Input\", fontsize=20)\n",
    "                    plt.gcf().text(0.02, 0.6, \"True I\", fontsize=20)\n",
    "                    plt.gcf().text(0.02, 0.4, \"Predicted I\", fontsize=20)\n",
    "                    plt.gcf().text(0.02, 0.2, \"Difference I\", fontsize=20)\n",
    "\n",
    "                    for i in range(0,n):\n",
    "                        j=int(round(np.random.rand()*(ntest-1)))\n",
    "\n",
    "                        # display FT\n",
    "                        im=ax[0,i].imshow(X_test[j].reshape(h, w), vmin=0, vmax=1)\n",
    "                        plt.colorbar(im, ax=ax[0,i], format='%.2f')\n",
    "                        ax[0,i].get_xaxis().set_visible(False)\n",
    "                        ax[0,i].get_yaxis().set_visible(False)\n",
    "\n",
    "                        # display original intens\n",
    "                        im=ax[1,i].imshow(Y_I_test[j].reshape(h, w))#, vmin=0, vmax=1)\n",
    "                        plt.colorbar(im, ax=ax[1,i], format='%.2f')\n",
    "                        ax[1,i].get_xaxis().set_visible(False)\n",
    "                        ax[1,i].get_yaxis().set_visible(False)\n",
    "                        \n",
    "                        # display predicted intens\n",
    "                        im=ax[2,i].imshow(results[j].reshape(h, w))#, vmin=0.0, vmax=1)\n",
    "                        plt.colorbar(im, ax=ax[2,i], format='%.2f')\n",
    "                        ax[2,i].get_xaxis().set_visible(False)\n",
    "                        ax[2,i].get_yaxis().set_visible(False)\n",
    "\n",
    "                        #Difference in amplitude\n",
    "                        im=ax[3,i].imshow(Y_I_test[j].reshape(h, w)-results[j].reshape(h, w), \n",
    "                                        vmin=-0.5, vmax=0.5, cmap='RdBu')\n",
    "                        plt.colorbar(im, ax=ax[3,i], format='%.2f')\n",
    "                        ax[3,i].get_xaxis().set_visible(False)\n",
    "                        ax[3,i].get_yaxis().set_visible(False)\n",
    "                    #plt.savefig(f'/scratch/plots/{directory}_{unet_status}_{loss_function}_symmetry_{symmetry_weight}_test.png', bbox_inches='tight', dpi=300)\n",
    "                    plt.savefig(f'/net/micdata/data2/12IDC/ptychosaxs/batch_mode_250/plots/{directory}_{unet_status}_{loss_function}_symmetry_{symmetry_weight}_test.png', bbox_inches='tight', dpi=300)\n",
    "                    plt.close()\n",
    "                    #plt.show()             "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptychosaxs_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
